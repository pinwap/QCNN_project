import copy
import logging
from abc import ABC, abstractmethod
from typing import List, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from qiskit import QuantumCircuit
from qiskit.circuit import ParameterVector
from qiskit.quantum_info import SparsePauliOp
from qiskit_machine_learning.connectors import TorchConnector
from qiskit_machine_learning.neural_networks import EstimatorQNN

from QCNN.DataManager import BaseDataManager
from QCNN.QCNN_structure import QCNNBuilder
from QCNN.QEA_core import QuantumChromosome

# Suppress Qiskit Machine Learning logging warnings about gradients
logging.getLogger("qiskit_machine_learning").setLevel(logging.ERROR)


class Evaluator(ABC):
    @abstractmethod
    def evaluate(
        self,
        structure_code: List[int],
        x_train: torch.Tensor,
        y_train: torch.Tensor,
        x_test: torch.Tensor,
        y_test: torch.Tensor,
    ) -> float:
        pass


class HybridEvaluator(Evaluator):
    def __init__(
        self,
        builder: QCNNBuilder,
        epochs: int = 5,
        lr: float = 0.01,
        verbose: bool = True,
    ):
        """
        builder: QCNNBuilder
        epochs: à¸ˆà¸³à¸™à¸§à¸™à¸£à¸­à¸šà¸à¸²à¸£à¸à¸¶à¸
        lr: learning rate
        """
        self.builder = builder
        self.epochs = epochs
        self.lr = lr
        self.verbose = verbose
        self.loss_fn = nn.MSELoss()

    def _create_feature_map(self, n_qubits: int = 16) -> Tuple[QuantumCircuit, ParameterVector]:
        # à¸ªà¸£à¹‰à¸²à¸‡à¸§à¸‡à¸ˆà¸£ Encode à¸‚à¹‰à¸­à¸¡à¸¹à¸¥ à¸”à¹‰à¸§à¸¢ Angle Encoding
        fm = QuantumCircuit(n_qubits)
        inputs = ParameterVector("input", n_qubits)
        for i in range(n_qubits):
            fm.rx(inputs[i] * np.pi, i)
        return fm, inputs

    def _crate_observable(self, last_qubit: int, n_qubits: int = 16) -> SparsePauliOp:
        # à¸ªà¸£à¹‰à¸²à¸‡à¸•à¸±à¸§à¸§à¸±à¸”à¸„à¹ˆà¸² Z à¸—à¸µà¹ˆ Qubit à¸ªà¸¸à¸”à¸—à¹‰à¸²à¸¢
        # qiskit à¹€à¸£à¸µà¸¢à¸‡ qubit à¸ˆà¸²à¸à¸‚à¸§à¸²à¹„à¸›à¸‹à¹‰à¸²à¸¢ !!!
        return SparsePauliOp.from_sparse_list([("Z", [last_qubit], 1)], num_qubits=n_qubits)

    def evaluate(
        self,
        structure_code: List[int],
        x_train: torch.Tensor,
        y_train: torch.Tensor,
        x_test: torch.Tensor,
        y_test: torch.Tensor,
    ) -> float:
        # Main Pipeline: Build -> Train -> Test -> Return Accuracy

        # 1. à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸¡à¹€à¸”à¸¥ QCNN à¸ˆà¸²à¸à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡
        qc, last_qubit = self.builder.assemble(structure_code)

        # 2. feature map & observe
        fm, input_params = self._create_feature_map(self.builder.n_qubits)
        observable = self._crate_observable(last_qubit, self.builder.n_qubits)

        # 3. à¸£à¸§à¸¡ feature map à¸à¸±à¸š QCNN
        full_circuit = QuantumCircuit(self.builder.n_qubits)
        full_circuit.append(fm, range(self.builder.n_qubits))
        full_circuit.append(qc, range(self.builder.n_qubits))

        # 4. define QNN
        qnn = EstimatorQNN(
            circuit=full_circuit,
            input_params=list(input_params),
            weight_params=list(qc.parameters),
            observables=observable,
        )

        # 5. Train Hybrid(Torch+Qiskit)
        model = TorchConnector(qnn)
        optimizer = optim.Adam(model.parameters(), lr=self.lr)

        model.train()
        for epoch in range(self.epochs):
            optimizer.zero_grad()
            output = model(x_train)
            loss = self.loss_fn(output, y_train.unsqueeze(1))
            loss.backward()
            optimizer.step()
            if self.verbose:
                print(f"    Epoch {epoch + 1}/{self.epochs}, Loss: {loss.item():.4f}")

        # 6. Test Accuracy
        model.eval()
        with torch.no_grad():
            preds = torch.sign(model(x_test))
            acc = (preds == y_test.unsqueeze(1)).float().mean().item()

        return acc


class Experiment:
    def __init__(
        self,
        data_mgr: BaseDataManager,
        evaluator: Evaluator,
        n_pop: int = 10,
        n_gen: int = 5,
        n_gates: int = 180,
    ):
        self.data_mgr = data_mgr  # Data Manager
        self.evaluator = evaluator
        self.n_gen = n_gen  # à¸ˆà¸³à¸™à¸§à¸™à¸£à¸¸à¹ˆà¸™

        # à¸ªà¸£à¹‰à¸²à¸‡à¸ˆà¸³à¸™à¸§à¸™à¸§à¸‡à¸ˆà¸£à¹€à¸£à¸´à¹ˆà¸¡à¸•à¹‰à¸™ n_pop à¸•à¸±à¸§à¹ƒà¸™ 1 à¸£à¸¸à¹ˆà¸™
        self.population = [QuantumChromosome(n_gates) for _ in range(n_pop)]
        self.global_best: Optional[QuantumChromosome] = None
        self.history: List[float] = []

    def _apply_crossover(self) -> None:
        print("Triggering Crossover")
        n_pop = len(self.population)
        n_genes = len(self.population[0].genes)

        # à¸ªà¸£à¹‰à¸²à¸‡ population à¹ƒà¸«à¸¡à¹ˆ à¸¡à¸²à¸£à¸­à¸£à¸±à¸šà¸„à¹ˆà¸²
        new_population = [p.copy() for p in self.population]

        for i in range(n_pop):
            for j in range(n_genes):
                # à¸ªà¸¹à¸•à¸£à¸•à¸²à¸¡ Table 2: à¸•à¸±à¸§à¸—à¸µà¹ˆ i à¸£à¸±à¸šà¸¢à¸µà¸™à¸•à¸³à¹à¸«à¸™à¹ˆà¸‡ j à¸¡à¸²à¸ˆà¸²à¸à¸•à¸±à¸§à¸—à¸µà¹ˆ (i+j)%N
                source_idx = (i + j) % n_pop
                # à¸à¹Šà¸­à¸›à¸›à¸µà¹‰ gene à¸¡à¸²à¹ƒà¸ªà¹ˆ (à¸•à¹‰à¸­à¸‡à¸£à¸°à¸§à¸±à¸‡à¹€à¸£à¸·à¹ˆà¸­à¸‡ pass by reference)
                new_population[i].genes[j] = copy.deepcopy(self.population[source_idx].genes[j])

        self.population = new_population

    def run(self) -> Tuple[Optional[QuantumChromosome], List[float]]:
        # 1. Prepair Data
        x_train, y_train, x_test, y_test = self.data_mgr.get_data()
        if x_train is None or y_train is None or x_test is None or y_test is None:
            print("Data loading failed. Experiment cannot proceed.")
            return None, []

        print(f"\nðŸš€ Start Experiment: {self.n_gen} Generations x {len(self.population)} Pop")

        stagnation_counter = 0

        for gen in range(self.n_gen):
            print(f"\n--- Generation {gen + 1}/{self.n_gen} ---")

            # 2. Loop Population
            for i, chromo in enumerate(self.population):
                print(f"  Evaluating Population {i + 1}/{len(self.population)}...")
                # A. Collapse -> Structure
                struct_code = chromo.collapse()

                # B. Train - Evaluate 5 Epochs
                acc = self.evaluator.evaluate(struct_code, x_train, y_train, x_test, y_test)
                chromo.fitness = acc
                print(f"  Pop {i + 1} Result: Acc = {acc:.4f}")

            # 3. Find Update Global Best
            current_best = max(self.population, key=lambda x: x.fitness)
            if self.global_best is None or current_best.fitness > self.global_best.fitness:
                self.global_best = current_best.copy()
                stagnation_counter = 0  # à¸£à¸µà¹€à¸‹à¹‡à¸•à¸™à¸±à¸šà¹ƒà¸«à¸¡à¹ˆ à¹€à¸žà¸£à¸²à¸°à¸„à¸°à¹à¸™à¸™à¸‚à¸¢à¸±à¸š
                print(f"  ðŸ† New Global Best: {self.global_best.fitness:.4f}")
            else:
                stagnation_counter += 1  # à¸„à¸°à¹à¸™à¸™à¹„à¸¡à¹ˆà¸‚à¸¢à¸±à¸š
                print(f" Stagnation: {stagnation_counter}/10")

            # 4. Evolution (Update Genes)
            if stagnation_counter >= 10:
                self._apply_crossover()
                stagnation_counter = 0  # à¸£à¸µà¹€à¸‹à¹‡à¸•à¸™à¸±à¸šà¹ƒà¸«à¸¡à¹ˆà¸«à¸¥à¸±à¸‡à¸„à¸£à¸­à¸ªà¹‚à¸­à¹€à¸§à¸­à¸£à¹Œ
            else:
                for chromo in self.population:
                    chromo.update_genes(self.global_best)

            self.history.append(self.global_best.fitness)

        return self.global_best, self.history
